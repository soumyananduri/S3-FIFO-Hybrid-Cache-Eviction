{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d995c3-502e-43d7-8028-74900aec9875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache MISS: Inserting A into Probationary Queue (P).\n",
      "\n",
      "Current Cache State:\n",
      "P (Probationary): ['A']\n",
      "M (Main): []\n",
      "G (Ghost): []\n",
      "Cache Hits: 0, Cache Misses: 1, Hit Ratio: 0.00\n",
      "\n",
      "Cache MISS: Inserting B into Probationary Queue (P).\n",
      "\n",
      "Current Cache State:\n",
      "P (Probationary): ['A', 'B']\n",
      "M (Main): []\n",
      "G (Ghost): []\n",
      "Cache Hits: 0, Cache Misses: 2, Hit Ratio: 0.00\n",
      "\n",
      "Cache MISS: Inserting C into Probationary Queue (P).\n",
      "\n",
      "Current Cache State:\n",
      "P (Probationary): ['A', 'B', 'C']\n",
      "M (Main): []\n",
      "G (Ghost): []\n",
      "Cache Hits: 0, Cache Misses: 3, Hit Ratio: 0.00\n",
      "\n",
      "Cache HIT (P): Promoted A to Main Queue (M).\n",
      "\n",
      "Current Cache State:\n",
      "P (Probationary): ['B', 'C']\n",
      "M (Main): ['A']\n",
      "G (Ghost): []\n",
      "Cache Hits: 1, Cache Misses: 3, Hit Ratio: 0.25\n",
      "\n",
      "Cache MISS: Inserting D into Probationary Queue (P).\n",
      "\n",
      "Current Cache State:\n",
      "P (Probationary): ['B', 'C', 'D']\n",
      "M (Main): ['A']\n",
      "G (Ghost): []\n",
      "Cache Hits: 1, Cache Misses: 4, Hit Ratio: 0.20\n",
      "\n",
      "Cache MISS: Inserting E into Probationary Queue (P).\n",
      "P Full: Evicted B to Ghost Queue (G).\n",
      "\n",
      "Current Cache State:\n",
      "P (Probationary): ['C', 'D', 'E']\n",
      "M (Main): ['A']\n",
      "G (Ghost): ['B']\n",
      "Cache Hits: 1, Cache Misses: 5, Hit Ratio: 0.17\n",
      "\n",
      "Cache MISS: Inserting B into Probationary Queue (P).\n",
      "P Full: Evicted C to Ghost Queue (G).\n",
      "\n",
      "Current Cache State:\n",
      "P (Probationary): ['D', 'E', 'B']\n",
      "M (Main): ['A']\n",
      "G (Ghost): ['B', 'C']\n",
      "Cache Hits: 1, Cache Misses: 6, Hit Ratio: 0.14\n",
      "\n",
      "Cache MISS: Inserting F into Probationary Queue (P).\n",
      "P Full: Evicted D to Ghost Queue (G).\n",
      "\n",
      "Current Cache State:\n",
      "P (Probationary): ['E', 'B', 'F']\n",
      "M (Main): ['A']\n",
      "G (Ghost): ['B', 'C', 'D']\n",
      "Cache Hits: 1, Cache Misses: 7, Hit Ratio: 0.12\n",
      "\n",
      "Cache MISS: Inserting G into Probationary Queue (P).\n",
      "P Full: Evicted E to Ghost Queue (G).\n",
      "\n",
      "Current Cache State:\n",
      "P (Probationary): ['B', 'F', 'G']\n",
      "M (Main): ['A']\n",
      "G (Ghost): ['B', 'C', 'D', 'E']\n",
      "Cache Hits: 1, Cache Misses: 8, Hit Ratio: 0.11\n",
      "\n",
      "Cache HIT (M): Refreshed A in Main Queue (M).\n",
      "\n",
      "Current Cache State:\n",
      "P (Probationary): ['B', 'F', 'G']\n",
      "M (Main): ['A']\n",
      "G (Ghost): ['B', 'C', 'D', 'E']\n",
      "Cache Hits: 2, Cache Misses: 8, Hit Ratio: 0.20\n",
      "\n",
      "Cache MISS: Inserting H into Probationary Queue (P).\n",
      "Adaptive Reinsertion: Reinserting B due to high access count.\n",
      "\n",
      "Current Cache State:\n",
      "P (Probationary): ['F', 'G', 'B', 'H']\n",
      "M (Main): ['A']\n",
      "G (Ghost): ['B', 'C', 'D', 'E']\n",
      "Cache Hits: 2, Cache Misses: 9, Hit Ratio: 0.18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import deque, defaultdict\n",
    "\n",
    "class S3FIFO_Cache_Adaptive:\n",
    "    def __init__(self, p_capacity, m_capacity, g_capacity):\n",
    "        # Initialising the three queues used in S3-FIFO\n",
    "        self.P = deque()  # Probationary Queue – for new items\n",
    "        self.M = deque()  # Main Queue – for promoted (frequently used) items\n",
    "        self.G = deque()  # Ghost Queue – stores metadata of evicted items\n",
    "\n",
    "        # Set queue capacity limits\n",
    "        self.p_capacity = p_capacity\n",
    "        self.m_capacity = m_capacity\n",
    "        self.g_capacity = g_capacity\n",
    "\n",
    "        # Used to keep track of what's currently in the cache (P + M)\n",
    "        self.cache_items = set()\n",
    "\n",
    "        # Used to track how often each item is accessed\n",
    "        self.access_count = defaultdict(int)\n",
    "\n",
    "        # For logging performance\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "\n",
    "    def access(self, item):\n",
    "        # Increment access frequency for every item\n",
    "        self.access_count[item] += 1\n",
    "\n",
    "        # If item is already in the cache → it's a hit\n",
    "        if item in self.cache_items:\n",
    "            self.hits += 1\n",
    "\n",
    "            if item in self.P:\n",
    "                # Promote from Probationary to Main if accessed again\n",
    "                self.P.remove(item)\n",
    "                self._add_to_main(item)\n",
    "                print(f\"Cache HIT (P): Promoted {item} to Main Queue (M).\")\n",
    "\n",
    "            elif item in self.M:\n",
    "                # Refresh position in Main to keep it recent\n",
    "                self.M.remove(item)\n",
    "                self.M.append(item)\n",
    "                print(f\"Cache HIT (M): Refreshed {item} in Main Queue (M).\")\n",
    "\n",
    "        else:\n",
    "            # If item is not in the cache → it's a miss\n",
    "            self.misses += 1\n",
    "            print(f\"Cache MISS: Inserting {item} into Probationary Queue (P).\")\n",
    "            self._add_to_probationary(item)\n",
    "\n",
    "    def _add_to_probationary(self, item):\n",
    "        # If P is full, evict the oldest item first\n",
    "        if len(self.P) >= self.p_capacity:\n",
    "            evicted = self.P.popleft()\n",
    "            self.cache_items.remove(evicted)\n",
    "\n",
    "            # Adaptive Reinsertion: if item has been accessed >= 2 times, give it another chance\n",
    "            if self.access_count[evicted] >= 2:\n",
    "                print(f\"Adaptive Reinsertion: Reinserting {evicted} due to high access count.\")\n",
    "                self._add_to_probationary(evicted)  # Reinsert it instead of fully evicting\n",
    "            else:\n",
    "                # If not accessed enough, send to Ghost\n",
    "                self._add_to_ghost(evicted)\n",
    "                print(f\"P Full: Evicted {evicted} to Ghost Queue (G).\")\n",
    "\n",
    "        # Add new item to P\n",
    "        self.P.append(item)\n",
    "        self.cache_items.add(item)\n",
    "\n",
    "    def _add_to_main(self, item):\n",
    "        # If M is full, evict the oldest item\n",
    "        if len(self.M) >= self.m_capacity:\n",
    "            evicted = self.M.popleft()\n",
    "            self.cache_items.remove(evicted)\n",
    "            self._add_to_ghost(evicted)\n",
    "            print(f\"M Full: Evicted {evicted} to Ghost Queue (G).\")\n",
    "\n",
    "        # Add the item to Main Queue\n",
    "        self.M.append(item)\n",
    "        self.cache_items.add(item)\n",
    "\n",
    "    def _add_to_ghost(self, item):\n",
    "        # Ghost queue only stores metadata – make sure it doesn't overflow\n",
    "        if len(self.G) >= self.g_capacity:\n",
    "            self.G.popleft()  # Just remove the oldest metadata\n",
    "        self.G.append(item)\n",
    "\n",
    "    def display(self):\n",
    "        # Print current state of the cache after each access\n",
    "        print(\"\\nCurrent Cache State:\")\n",
    "        print(f\"P (Probationary): {list(self.P)}\")\n",
    "        print(f\"M (Main): {list(self.M)}\")\n",
    "        print(f\"G (Ghost): {list(self.G)}\")\n",
    "        print(f\"Cache Hits: {self.hits}, Cache Misses: {self.misses}, Hit Ratio: {self.hits / (self.hits + self.misses):.2f}\\n\")\n",
    "\n",
    "\n",
    "# Sample usage and test access pattern\n",
    "if __name__ == \"__main__\":\n",
    "    # Initializing cache with custom queue sizes\n",
    "    cache = S3FIFO_Cache_Adaptive(p_capacity=3, m_capacity=3, g_capacity=5)\n",
    "\n",
    "    # Access sequence to simulate a real-world workload\n",
    "    sequence = ['A', 'B', 'C', 'A', 'D', 'E', 'B', 'F', 'G', 'A', 'H']\n",
    "\n",
    "    for item in sequence:\n",
    "        cache.access(item)\n",
    "        cache.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b502f2-e59c-4824-8a85-4a7a3f894b84",
   "metadata": {},
   "source": [
    "Stage-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e85f18ae-0d32-46de-bcf9-19e91d8c0b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "class S3FIFO_Cache_Adaptive:\n",
    "    def __init__(self, p_capacity, m_capacity, g_capacity, reinsertion_threshold=2, log_file=\"cache_log.csv\"):\n",
    "        # Initialising the three queues: Probationary (P), Main (M), and Ghost (G)\n",
    "        self.P = deque()\n",
    "        self.M = deque()\n",
    "        self.G = deque()\n",
    "\n",
    "        # Setting the maximum sizes for each queue\n",
    "        self.p_capacity = p_capacity\n",
    "        self.m_capacity = m_capacity\n",
    "        self.g_capacity = g_capacity\n",
    "\n",
    "        # Reinsertion threshold: minimum number of accesses before reinsert is allowed\n",
    "        self.reinsertion_threshold = reinsertion_threshold\n",
    "\n",
    "        # Tracks which items are currently in cache (P or M)\n",
    "        self.cache_items = set()\n",
    "\n",
    "        # Tracks how many times each item was accessed\n",
    "        self.access_count = defaultdict(int)\n",
    "\n",
    "        # Counters for basic cache performance\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "        self.reinserts = 0\n",
    "        self.access_step = 0  # Used to track step number for logging\n",
    "\n",
    "        # CSV logging setup\n",
    "        self.log_file = log_file\n",
    "        self._init_log()\n",
    "\n",
    "    # Creates the header row in the CSV log file\n",
    "    def _init_log(self):\n",
    "        with open(self.log_file, mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"step\", \"item\", \"status\", \"P\", \"M\", \"G\", \"reinserts\", \"hit_ratio\"])\n",
    "\n",
    "    # Logs each access to CSV for future analysis/plotting\n",
    "    def _log_access(self, item, status):\n",
    "        total = self.hits + self.misses\n",
    "        hit_ratio = self.hits / total if total > 0 else 0\n",
    "\n",
    "        with open(self.log_file, mode='a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                self.access_step,\n",
    "                item,\n",
    "                status,\n",
    "                list(self.P),\n",
    "                list(self.M),\n",
    "                list(self.G),\n",
    "                self.reinserts,\n",
    "                round(hit_ratio, 4)\n",
    "            ])\n",
    "\n",
    "    # Main method to process each access request\n",
    "    def access(self, item):\n",
    "        self.access_step += 1\n",
    "        self.access_count[item] += 1  # Increase access frequency\n",
    "\n",
    "        if item in self.cache_items:\n",
    "            self.hits += 1\n",
    "            if item in self.P:\n",
    "                # Promote to Main queue if accessed again\n",
    "                self.P.remove(item)\n",
    "                self._add_to_main(item)\n",
    "                status = \"HIT-P → M\"\n",
    "            elif item in self.M:\n",
    "                # Refresh position in Main queue (optional but common)\n",
    "                self.M.remove(item)\n",
    "                self.M.append(item)\n",
    "                status = \"HIT-M\"\n",
    "        else:\n",
    "            self.misses += 1\n",
    "            status = \"MISS\"\n",
    "            self._add_to_probationary(item)\n",
    "\n",
    "        # Log this access\n",
    "        self._log_access(item, status)\n",
    "\n",
    "    # Logic for inserting into P, with adaptive reinsertion\n",
    "    def _add_to_probationary(self, item):\n",
    "        if len(self.P) >= self.p_capacity:\n",
    "            evicted = self.P.popleft()\n",
    "            self.cache_items.remove(evicted)\n",
    "\n",
    "            # Check access frequency before deciding on reinsertion\n",
    "            if self.access_count[evicted] >= self.reinsertion_threshold:\n",
    "                self.reinserts += 1\n",
    "                self._add_to_probationary(evicted)\n",
    "                return  # Exit to avoid double inserting `item`\n",
    "            else:\n",
    "                self._add_to_ghost(evicted)\n",
    "\n",
    "        # Add the current item to P\n",
    "        self.P.append(item)\n",
    "        self.cache_items.add(item)\n",
    "\n",
    "    # Logic for adding to Main queue (M), evicting if necessary\n",
    "    def _add_to_main(self, item):\n",
    "        if len(self.M) >= self.m_capacity:\n",
    "            evicted = self.M.popleft()\n",
    "            self.cache_items.remove(evicted)\n",
    "            self._add_to_ghost(evicted)\n",
    "\n",
    "        self.M.append(item)\n",
    "        self.cache_items.add(item)\n",
    "\n",
    "    # Add evicted items to Ghost queue (G), maintaining G's size limit\n",
    "    def _add_to_ghost(self, item):\n",
    "        if len(self.G) >= self.g_capacity:\n",
    "            self.G.popleft()\n",
    "        self.G.append(item)\n",
    "\n",
    "    # Print cache summary after each access (useful for debugging or terminal output)\n",
    "    def display(self):\n",
    "        total = self.hits + self.misses\n",
    "        hit_ratio = self.hits / total if total > 0 else 0\n",
    "        print(f\"Step: {self.access_step}\")\n",
    "        print(f\"Cache Hits: {self.hits}, Misses: {self.misses}, Hit Ratio: {hit_ratio:.2f}\")\n",
    "        print(f\"Reinsertions: {self.reinserts}\")\n",
    "        print(f\"P: {list(self.P)}\\nM: {list(self.M)}\\nG: {list(self.G)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8f8fb67-7d85-43e7-a510-06e9e1174066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\n",
      "Cache Hits: 0, Misses: 1, Hit Ratio: 0.00\n",
      "Reinsertions: 0\n",
      "P: ['A']\n",
      "M: []\n",
      "G: []\n",
      "\n",
      "Step: 2\n",
      "Cache Hits: 0, Misses: 2, Hit Ratio: 0.00\n",
      "Reinsertions: 0\n",
      "P: ['A', 'B']\n",
      "M: []\n",
      "G: []\n",
      "\n",
      "Step: 3\n",
      "Cache Hits: 0, Misses: 3, Hit Ratio: 0.00\n",
      "Reinsertions: 0\n",
      "P: ['A', 'B', 'C']\n",
      "M: []\n",
      "G: []\n",
      "\n",
      "Step: 4\n",
      "Cache Hits: 1, Misses: 3, Hit Ratio: 0.25\n",
      "Reinsertions: 0\n",
      "P: ['B', 'C']\n",
      "M: ['A']\n",
      "G: []\n",
      "\n",
      "Step: 5\n",
      "Cache Hits: 1, Misses: 4, Hit Ratio: 0.20\n",
      "Reinsertions: 0\n",
      "P: ['B', 'C', 'D']\n",
      "M: ['A']\n",
      "G: []\n",
      "\n",
      "Step: 6\n",
      "Cache Hits: 1, Misses: 5, Hit Ratio: 0.17\n",
      "Reinsertions: 0\n",
      "P: ['C', 'D', 'E']\n",
      "M: ['A']\n",
      "G: ['B']\n",
      "\n",
      "Step: 7\n",
      "Cache Hits: 1, Misses: 6, Hit Ratio: 0.14\n",
      "Reinsertions: 0\n",
      "P: ['D', 'E', 'B']\n",
      "M: ['A']\n",
      "G: ['B', 'C']\n",
      "\n",
      "Step: 8\n",
      "Cache Hits: 1, Misses: 7, Hit Ratio: 0.12\n",
      "Reinsertions: 0\n",
      "P: ['E', 'B', 'F']\n",
      "M: ['A']\n",
      "G: ['B', 'C', 'D']\n",
      "\n",
      "Step: 9\n",
      "Cache Hits: 1, Misses: 8, Hit Ratio: 0.11\n",
      "Reinsertions: 0\n",
      "P: ['B', 'F', 'G']\n",
      "M: ['A']\n",
      "G: ['B', 'C', 'D', 'E']\n",
      "\n",
      "Step: 10\n",
      "Cache Hits: 2, Misses: 8, Hit Ratio: 0.20\n",
      "Reinsertions: 0\n",
      "P: ['B', 'F', 'G']\n",
      "M: ['A']\n",
      "G: ['B', 'C', 'D', 'E']\n",
      "\n",
      "Step: 11\n",
      "Cache Hits: 2, Misses: 9, Hit Ratio: 0.18\n",
      "Reinsertions: 1\n",
      "P: ['F', 'G', 'B']\n",
      "M: ['A']\n",
      "G: ['B', 'C', 'D', 'E']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    cache = S3FIFO_Cache_Adaptive(p_capacity=3, m_capacity=3, g_capacity=5, reinsertion_threshold=2)\n",
    "\n",
    "    sequence = ['A', 'B', 'C', 'A', 'D', 'E', 'B', 'F', 'G', 'A', 'H']\n",
    "\n",
    "    for item in sequence:\n",
    "        cache.access(item)\n",
    "        cache.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f92c11-f85e-4301-9f6d-25bbf471fa80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed07f97-e0b2-4c67-b75c-18e2679726b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "\n",
    "# Generating a synthetic trace to simulate access patterns like ATLAS (bursty)\n",
    "def generate_atlas_trace(n_requests=1000, unique_items=100):\n",
    "    trace = []\n",
    "    # I’m creating 5 small “hot” sets (10 items each) that get accessed more often\n",
    "    hot_sets = [random.sample(range(unique_items), 10) for _ in range(5)]\n",
    "    for _ in range(n_requests):\n",
    "        if random.random() < 0.7:\n",
    "            # 70% of the time, pick from a hot set (bursty behavior)\n",
    "            hot_set = random.choice(hot_sets)\n",
    "            trace.append(random.choice(hot_set))\n",
    "        else:\n",
    "            # The rest are just random items (noise)\n",
    "            trace.append(random.randint(0, unique_items - 1))\n",
    "    return trace\n",
    "\n",
    "# Simulating a skewed frequency pattern like Google Search using a Zipf-like distribution\n",
    "def generate_google_trace(n_requests=1000, unique_items=100):\n",
    "    trace = []\n",
    "    # Create a Zipfian weight distribution (more popular items get accessed more)\n",
    "    weights = [1 / (i + 1) for i in range(unique_items)]\n",
    "    items = list(range(unique_items))\n",
    "    for _ in range(n_requests):\n",
    "        # Heavily skewed selection — popular items dominate\n",
    "        trace.append(random.choices(items, weights=weights)[0])\n",
    "    return trace\n",
    "\n",
    "# Simulating a CDN-like pattern — periodic access to small groups of items\n",
    "def generate_cdn_trace(n_requests=1000, unique_items=100):\n",
    "    trace = []\n",
    "    wave_size = 10\n",
    "    # I break items into groups of 10, then access each wave cyclically\n",
    "    waves = [list(range(i, i + wave_size)) for i in range(0, unique_items, wave_size)]\n",
    "    for i in range(n_requests):\n",
    "        wave = waves[(i // wave_size) % len(waves)]\n",
    "        trace.append(random.choice(wave))\n",
    "    return trace\n",
    "\n",
    "# Save the generated trace to a CSV file (to feed into the cache system later)\n",
    "def save_trace_to_csv(trace, filename=\"trace.csv\"):\n",
    "    with open(filename, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"access_item\"])  # header\n",
    "        for item in trace:\n",
    "            writer.writerow([item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bffebcf6-2a8e-4398-8b96-3c6ed59768d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating and saving all 3 workload traces\n",
    "\n",
    "# Generate traces\n",
    "atlas = generate_atlas_trace()\n",
    "google = generate_google_trace()\n",
    "cdn = generate_cdn_trace()\n",
    "\n",
    "# Save each one to its own CSV\n",
    "save_trace_to_csv(atlas, \"atlas_trace.csv\")\n",
    "save_trace_to_csv(google, \"google_trace.csv\")\n",
    "save_trace_to_csv(cdn, \"cdn_trace.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc81007-6c91-4fb4-9ef9-15efe5701a0d",
   "metadata": {},
   "source": [
    "With atlas trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91038181-f7e9-432f-a98d-84b264d1663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5000\n",
      "Cache Hits: 3596, Misses: 1404, Hit Ratio: 0.72\n",
      "Reinsertions: 776\n",
      "P: ['271', '258', '15', '92', '237', '165', '37', '100', '78', '155', '289', '287', '269', '146', '238', '41', '242', '1', '95', '50', '71', '280', '80', '14', '109', '154', '279', '144', '91', '121', '296', '259', '226', '276', '139', '243', '86', '263', '61', '124', '128', '115', '18', '179', '25', '225', '7', '257', '135', '129']\n",
      "M: ['108', '58', '219', '36', '297', '42', '4', '84', '212', '176', '274', '261', '298', '166', '69', '152', '253', '245', '252', '286', '119', '114', '209', '241', '290', '249', '73', '145', '234', '40', '229', '248', '221', '188', '123', '113', '122', '299', '189', '201', '173', '267', '291', '254', '177', '250', '195', '21', '45', '169']\n",
      "G: ['213', '166', '226', '144', '10', '285', '254', '280', '54', '163', '274', '113', '244', '12', '298', '189', '42', '1', '43', '173', '36', '145', '177', '81', '227', '217', '154', '291', '186', '261', '272', '115', '89', '243', '85', '22', '84', '120', '219', '166', '220', '62', '35', '66', '260', '132', '38', '136', '254', '111', '191', '267', '56', '165', '58', '76', '255', '40', '209', '239', '298', '187', '213', '235', '103', '152', '167', '166', '23', '269', '69', '258', '130', '283', '56', '119', '158', '133', '57', '77', '106', '137', '216', '97', '125', '185', '74', '9', '151', '87', '164', '12', '270', '121', '296', '0', '144', '96', '72', '277']\n",
      "\n",
      "Step: 6000\n",
      "Cache Hits: 4347, Misses: 1653, Hit Ratio: 0.72\n",
      "Reinsertions: 962\n",
      "P: ['94', '100', '88', '155', '289', '287', '269', '146', '238', '242', '280', '109', '154', '279', '51', '144', '121', '296', '259', '226', '56', '276', '139', '243', '86', '263', '124', '128', '115', '179', '29', '225', '66', '70', '257', '135', '129', '271', '73', '62', '99', '22', '65', '258', '237', '75', '52', '79', '72', '165']\n",
      "M: ['19', '84', '58', '55', '93', '25', '31', '45', '17', '69', '48', '30', '21', '78', '57', '35', '15', '23', '5', '27', '9', '42', '12', '64', '20', '53', '68', '16', '7', '13', '50', '44', '10', '4', '76', '87', '40', '38', '95', '28', '46', '8', '1', '6', '91', '2', '3', '77', '11', '0']\n",
      "G: ['235', '103', '152', '167', '166', '23', '269', '69', '258', '130', '283', '56', '119', '158', '133', '57', '77', '106', '137', '216', '97', '125', '185', '74', '9', '151', '87', '164', '12', '270', '121', '296', '0', '144', '96', '72', '277', '108', '58', '219', '36', '297', '42', '84', '212', '176', '274', '261', '298', '166', '152', '253', '245', '252', '286', '119', '114', '209', '241', '290', '249', '73', '145', '234', '229', '248', '221', '188', '123', '113', '122', '299', '189', '201', '173', '267', '291', '254', '177', '250', '195', '169', '85', '71', '37', '49', '38', '80', '98', '47', '97', '24', '60', '74', '14', '36', '41', '18', '61', '92']\n",
      "\n",
      "Step: 7000\n",
      "Cache Hits: 5039, Misses: 1961, Hit Ratio: 0.72\n",
      "Reinsertions: 1117\n",
      "P: ['289', '287', '269', '146', '238', '242', '280', '109', '154', '279', '144', '121', '296', '259', '15', '30', '226', '276', '139', '243', '263', '124', '128', '66', '8', '11', '14', '20', '21', '28', '46', '48', '59', '53', '55', '58', '56', '61', '115', '179', '225', '257', '135', '129', '271', '258', '237', '165', '100', '155']\n",
      "M: ['71', '81', '83', '98', '92', '0', '5', '9', '4', '1', '3', '10', '19', '17', '13', '12', '24', '27', '22', '26', '25', '38', '36', '35', '32', '34', '40', '49', '42', '47', '57', '52', '54', '60', '65', '62', '68', '63', '74', '73', '77', '70', '75', '84', '80', '87', '93', '95', '90', '97']\n",
      "G: ['82', '89', '87', '91', '97', '8', '1', '0', '10', '26', '22', '38', '35', '46', '44', '64', '79', '76', '83', '94', '92', '96', '5', '9', '11', '17', '25', '29', '34', '58', '70', '72', '71', '85', '93', '95', '90', '7', '12', '18', '15', '28', '23', '32', '30', '36', '37', '49', '45', '43', '51', '59', '56', '60', '66', '74', '99', '2', '8', '24', '31', '47', '42', '53', '50', '61', '69', '70', '75', '76', '81', '89', '7', '14', '21', '20', '39', '33', '46', '51', '54', '62', '79', '72', '78', '82', '85', '88', '86', '94', '96', '6', '16', '29', '23', '37', '48', '55', '64', '67']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "# -----------------------\n",
    "# 1. Trace Generators\n",
    "# -----------------------\n",
    "\n",
    "def generate_atlas_trace(n_requests=5000, unique_items=300):\n",
    "    trace = []\n",
    "    hot_sets = [random.sample(range(unique_items), 10) for _ in range(5)]\n",
    "    for _ in range(n_requests):\n",
    "        if random.random() < 0.7:\n",
    "            hot_set = random.choice(hot_sets)\n",
    "            trace.append(random.choice(hot_set))\n",
    "        else:\n",
    "            trace.append(random.randint(0, unique_items - 1))\n",
    "    return trace\n",
    "\n",
    "def save_trace_to_csv(trace, filename=\"atlas_trace.csv\"):\n",
    "    with open(filename, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"access_item\"])\n",
    "        for item in trace:\n",
    "            writer.writerow([item])\n",
    "\n",
    "# -----------------------\n",
    "# 2. Cache Implementation\n",
    "# -----------------------\n",
    "\n",
    "class S3FIFO_Cache_Adaptive:\n",
    "    def __init__(self, p_capacity, m_capacity, g_capacity, reinsertion_threshold=2, log_file=\"cache_log.csv\"):\n",
    "        self.P = deque()\n",
    "        self.M = deque()\n",
    "        self.G = deque()\n",
    "\n",
    "        self.p_capacity = p_capacity\n",
    "        self.m_capacity = m_capacity\n",
    "        self.g_capacity = g_capacity\n",
    "        self.reinsertion_threshold = reinsertion_threshold\n",
    "\n",
    "        self.cache_items = set()\n",
    "        self.access_count = defaultdict(int)\n",
    "\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "        self.reinserts = 0\n",
    "        self.access_step = 0\n",
    "\n",
    "        self.log_file = log_file\n",
    "        self._init_log()\n",
    "\n",
    "    def _init_log(self):\n",
    "        with open(self.log_file, mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"step\", \"item\", \"status\", \"P\", \"M\", \"G\", \"reinserts\", \"hit_ratio\"])\n",
    "\n",
    "    def _log_access(self, item, status):\n",
    "        total = self.hits + self.misses\n",
    "        hit_ratio = self.hits / total if total > 0 else 0\n",
    "        with open(self.log_file, mode='a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                self.access_step,\n",
    "                item,\n",
    "                status,\n",
    "                list(self.P),\n",
    "                list(self.M),\n",
    "                list(self.G),\n",
    "                self.reinserts,\n",
    "                round(hit_ratio, 4)\n",
    "            ])\n",
    "\n",
    "    def access(self, item):\n",
    "        self.access_step += 1\n",
    "        self.access_count[item] += 1\n",
    "\n",
    "        if item in self.cache_items:\n",
    "            self.hits += 1\n",
    "            if item in self.P:\n",
    "                self.P.remove(item)\n",
    "                self._add_to_main(item)\n",
    "                status = \"HIT-P → M\"\n",
    "            elif item in self.M:\n",
    "                self.M.remove(item)\n",
    "                self.M.append(item)\n",
    "                status = \"HIT-M\"\n",
    "        else:\n",
    "            self.misses += 1\n",
    "            status = \"MISS\"\n",
    "            self._add_to_probationary(item)\n",
    "\n",
    "        self._log_access(item, status)\n",
    "\n",
    "    def _add_to_probationary(self, item):\n",
    "        if len(self.P) >= self.p_capacity:\n",
    "            evicted = self.P.popleft()\n",
    "            self.cache_items.remove(evicted)\n",
    "            if self.access_count[evicted] >= self.reinsertion_threshold:\n",
    "                self.reinserts += 1\n",
    "                self._add_to_probationary(evicted)\n",
    "                return\n",
    "            else:\n",
    "                self._add_to_ghost(evicted)\n",
    "        self.P.append(item)\n",
    "        self.cache_items.add(item)\n",
    "\n",
    "    def _add_to_main(self, item):\n",
    "        if len(self.M) >= self.m_capacity:\n",
    "            evicted = self.M.popleft()\n",
    "            self.cache_items.remove(evicted)\n",
    "            self._add_to_ghost(evicted)\n",
    "        self.M.append(item)\n",
    "        self.cache_items.add(item)\n",
    "\n",
    "    def _add_to_ghost(self, item):\n",
    "        if len(self.G) >= self.g_capacity:\n",
    "            self.G.popleft()\n",
    "        self.G.append(item)\n",
    "\n",
    "    def display(self):\n",
    "        total = self.hits + self.misses\n",
    "        hit_ratio = self.hits / total if total > 0 else 0\n",
    "        print(f\"Step: {self.access_step}\")\n",
    "        print(f\"Cache Hits: {self.hits}, Misses: {self.misses}, Hit Ratio: {hit_ratio:.2f}\")\n",
    "        print(f\"Reinsertions: {self.reinserts}\")\n",
    "        print(f\"P: {list(self.P)}\\nM: {list(self.M)}\\nG: {list(self.G)}\\n\")\n",
    "\n",
    "# -----------------------\n",
    "# 3. Run Simulation\n",
    "# -----------------------\n",
    "\n",
    "def run_trace_from_csv(trace_file, cache):\n",
    "    with open(trace_file, mode='r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            item = row[\"access_item\"]\n",
    "            cache.access(item)\n",
    "    cache.display()\n",
    "\n",
    "# -----------------------\n",
    "# 4. Main Execution Block\n",
    "# -----------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate a trace\n",
    "    trace = generate_atlas_trace(n_requests=5000, unique_items=300)\n",
    "    save_trace_to_csv(trace, filename=\"atlas_trace.csv\")\n",
    "    save_trace_to_csv(generate_google_trace(), filename=\"google_trace.csv\")\n",
    "    save_trace_to_csv(generate_cdn_trace(), filename=\"cdn_trace.csv\")\n",
    "\n",
    "    # Run it through the cache system\n",
    "    cache = S3FIFO_Cache_Adaptive(p_capacity=50, m_capacity=50, g_capacity=100)\n",
    "    run_trace_from_csv(\"atlas_trace.csv\", cache)\n",
    "    run_trace_from_csv(\"google_trace.csv\", cache)\n",
    "    run_trace_from_csv(\"cdn_trace.csv\", cache)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52342a29-8116-4fd1-bc32-77e4de8e75f9",
   "metadata": {},
   "source": [
    "Adding Rolling Hit Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a2f2db5-e170-4ffd-8409-0e39472b6653",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deque  \u001b[38;5;66;03m# Already imported\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mrolling_window \u001b[38;5;241m=\u001b[39m deque(maxlen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrolling_ratios \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# to store rolling ratio per step\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import deque  # Already imported\n",
    "\n",
    "self.rolling_window = deque(maxlen=100)\n",
    "self.rolling_ratios = []  # to store rolling ratio per step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43333743-1798-42df-926e-1aaca0b250a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5000\n",
      "Cache Hits: 3520, Misses: 1480, Hit Ratio: 0.70\n",
      "Reinsertions: 888\n",
      "P: ['137', '225', '227', '190', '22', '222', '164', '68', '242', '151', '176', '162', '152', '247', '50', '153', '35', '267', '44', '290', '115', '135', '232', '235', '180', '27', '127', '46', '238', '215', '58', '212', '73', '205', '213', '30', '248', '121', '29', '217', '277', '76', '280', '75', '5', '233', '2', '144', '9', '268']\n",
      "M: ['188', '17', '253', '275', '103', '16', '229', '126', '178', '174', '218', '286', '116', '59', '255', '120', '136', '241', '62', '111', '230', '49', '95', '106', '79', '36', '263', '177', '118', '4', '287', '168', '110', '289', '149', '288', '41', '96', '150', '72', '114', '297', '265', '0', '216', '93', '48', '140', '70', '138']\n",
      "G: ['101', '234', '108', '144', '167', '203', '158', '192', '188', '191', '4', '152', '247', '127', '130', '216', '99', '3', '265', '166', '2', '294', '274', '105', '129', '250', '209', '0', '103', '215', '172', '136', '111', '162', '84', '297', '93', '177', '64', '288', '120', '279', '207', '42', '148', '142', '211', '122', '278', '95', '226', '242', '10', '241', '123', '86', '138', '178', '239', '16', '255', '216', '286', '0', '99', '26', '168', '65', '114', '218', '275', '259', '101', '248', '281', '263', '229', '193', '47', '179', '200', '55', '100', '12', '276', '270', '285', '284', '61', '146', '233', '249', '234', '202', '173', '257', '208', '189', '117', '51']\n",
      "\n",
      "Step: 5000\n",
      "Cache Hits: 3520, Misses: 1480, Hit Ratio: 0.70\n",
      "Reinsertions: 888\n",
      "P: ['137', '225', '227', '190', '22', '222', '164', '68', '242', '151', '176', '162', '152', '247', '50', '153', '35', '267', '44', '290', '115', '135', '232', '235', '180', '27', '127', '46', '238', '215', '58', '212', '73', '205', '213', '30', '248', '121', '29', '217', '277', '76', '280', '75', '5', '233', '2', '144', '9', '268']\n",
      "M: ['188', '17', '253', '275', '103', '16', '229', '126', '178', '174', '218', '286', '116', '59', '255', '120', '136', '241', '62', '111', '230', '49', '95', '106', '79', '36', '263', '177', '118', '4', '287', '168', '110', '289', '149', '288', '41', '96', '150', '72', '114', '297', '265', '0', '216', '93', '48', '140', '70', '138']\n",
      "G: ['101', '234', '108', '144', '167', '203', '158', '192', '188', '191', '4', '152', '247', '127', '130', '216', '99', '3', '265', '166', '2', '294', '274', '105', '129', '250', '209', '0', '103', '215', '172', '136', '111', '162', '84', '297', '93', '177', '64', '288', '120', '279', '207', '42', '148', '142', '211', '122', '278', '95', '226', '242', '10', '241', '123', '86', '138', '178', '239', '16', '255', '216', '286', '0', '99', '26', '168', '65', '114', '218', '275', '259', '101', '248', '281', '263', '229', '193', '47', '179', '200', '55', '100', '12', '276', '270', '285', '284', '61', '146', '233', '249', '234', '202', '173', '257', '208', '189', '117', '51']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "class S3FIFO_Cache_Adaptive:\n",
    "    def __init__(self, p_capacity, m_capacity, g_capacity, reinsertion_threshold=2, log_file=\"cache_log.csv\"):\n",
    "        # Queues\n",
    "        self.P = deque()\n",
    "        self.M = deque()\n",
    "        self.G = deque()\n",
    "\n",
    "        # Capacities\n",
    "        self.p_capacity = p_capacity\n",
    "        self.m_capacity = m_capacity\n",
    "        self.g_capacity = g_capacity\n",
    "        self.reinsertion_threshold = reinsertion_threshold\n",
    "\n",
    "        # Track active items and metadata\n",
    "        self.cache_items = set()\n",
    "        self.access_count = defaultdict(int)\n",
    "\n",
    "        # Stats\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "        self.reinserts = 0\n",
    "        self.access_step = 0\n",
    "\n",
    "        # Rolling hit ratio tracker\n",
    "        self.rolling_window = deque(maxlen=100)  # tracks last 100 results (1=hit, 0=miss)\n",
    "        self.rolling_ratios = []  # stores rolling hit ratio over time\n",
    "\n",
    "        # CSV log\n",
    "        self.log_file = log_file\n",
    "        self._init_log()\n",
    "\n",
    "    def _init_log(self):\n",
    "        with open(self.log_file, mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                \"step\", \"item\", \"status\", \"P\", \"M\", \"G\",\n",
    "                \"reinserts\", \"hit_ratio\", \"rolling_hit_ratio\"\n",
    "            ])\n",
    "\n",
    "    def _log_access(self, item, status):\n",
    "        total = self.hits + self.misses\n",
    "        hit_ratio = self.hits / total if total > 0 else 0\n",
    "\n",
    "        # Update rolling window and calculate rolling hit ratio\n",
    "        self.rolling_window.append(1 if status.startswith(\"HIT\") else 0)\n",
    "        rolling_ratio = sum(self.rolling_window) / len(self.rolling_window)\n",
    "        self.rolling_ratios.append(rolling_ratio)\n",
    "\n",
    "        with open(self.log_file, mode='a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                self.access_step,\n",
    "                item,\n",
    "                status,\n",
    "                list(self.P),\n",
    "                list(self.M),\n",
    "                list(self.G),\n",
    "                self.reinserts,\n",
    "                round(hit_ratio, 4),\n",
    "                round(rolling_ratio, 4)\n",
    "            ])\n",
    "\n",
    "    def access(self, item):\n",
    "        self.access_step += 1\n",
    "        self.access_count[item] += 1\n",
    "\n",
    "        if item in self.cache_items:\n",
    "            self.hits += 1\n",
    "            if item in self.P:\n",
    "                self.P.remove(item)\n",
    "                self._add_to_main(item)\n",
    "                status = \"HIT-P → M\"\n",
    "            elif item in self.M:\n",
    "                self.M.remove(item)\n",
    "                self.M.append(item)\n",
    "                status = \"HIT-M\"\n",
    "        else:\n",
    "            self.misses += 1\n",
    "            status = \"MISS\"\n",
    "            self._add_to_probationary(item)\n",
    "\n",
    "        self._log_access(item, status)\n",
    "\n",
    "    def _add_to_probationary(self, item):\n",
    "        if len(self.P) >= self.p_capacity:\n",
    "            evicted = self.P.popleft()\n",
    "            self.cache_items.remove(evicted)\n",
    "\n",
    "            if self.access_count[evicted] >= self.reinsertion_threshold:\n",
    "                self.reinserts += 1\n",
    "                self._add_to_probationary(evicted)\n",
    "                return\n",
    "            else:\n",
    "                self._add_to_ghost(evicted)\n",
    "\n",
    "        self.P.append(item)\n",
    "        self.cache_items.add(item)\n",
    "\n",
    "    def _add_to_main(self, item):\n",
    "        if len(self.M) >= self.m_capacity:\n",
    "            evicted = self.M.popleft()\n",
    "            self.cache_items.remove(evicted)\n",
    "            self._add_to_ghost(evicted)\n",
    "\n",
    "        self.M.append(item)\n",
    "        self.cache_items.add(item)\n",
    "\n",
    "    def _add_to_ghost(self, item):\n",
    "        if len(self.G) >= self.g_capacity:\n",
    "            self.G.popleft()\n",
    "        self.G.append(item)\n",
    "\n",
    "    def display(self):\n",
    "        total = self.hits + self.misses\n",
    "        hit_ratio = self.hits / total if total > 0 else 0\n",
    "        print(f\"Step: {self.access_step}\")\n",
    "        print(f\"Cache Hits: {self.hits}, Misses: {self.misses}, Hit Ratio: {hit_ratio:.2f}\")\n",
    "        print(f\"Reinsertions: {self.reinserts}\")\n",
    "        print(f\"P: {list(self.P)}\")\n",
    "        print(f\"M: {list(self.M)}\")\n",
    "        print(f\"G: {list(self.G)}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Generate and save trace\n",
    "    trace = generate_atlas_trace(n_requests=5000, unique_items=300)\n",
    "    save_trace_to_csv(trace, filename=\"atlas_trace.csv\")\n",
    "\n",
    "    # Step 2: Initialize cache and run simulation\n",
    "    cache = S3FIFO_Cache_Adaptive(\n",
    "        p_capacity=50,\n",
    "        m_capacity=50,\n",
    "        g_capacity=100,\n",
    "        reinsertion_threshold=2,\n",
    "        log_file=\"atlas_log.csv\"\n",
    "    )\n",
    "\n",
    "    run_trace_from_csv(\"atlas_trace.csv\", cache)\n",
    "\n",
    "    # Step 3: Print final cache summary\n",
    "    cache.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab083d0-3247-48f4-8504-374116f5a173",
   "metadata": {},
   "source": [
    "Dynamic Reinsertion logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5b3748f-fd6b-4024-89de-3d14bf97679a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoTune] Step 100: Rolling Hit Ratio = 0.39 | Threshold = 3\n",
      "[AutoTune] Step 200: Rolling Hit Ratio = 0.71 | Threshold = 4\n",
      "[AutoTune] Step 300: Rolling Hit Ratio = 0.81 | Threshold = 5\n",
      "[AutoTune] Step 400: Rolling Hit Ratio = 0.78 | Threshold = 4\n",
      "[AutoTune] Step 500: Rolling Hit Ratio = 0.76 | Threshold = 3\n",
      "[AutoTune] Step 600: Rolling Hit Ratio = 0.72 | Threshold = 2\n",
      "[AutoTune] Step 700: Rolling Hit Ratio = 0.73 | Threshold = 2\n",
      "[AutoTune] Step 800: Rolling Hit Ratio = 0.76 | Threshold = 3\n",
      "[AutoTune] Step 900: Rolling Hit Ratio = 0.75 | Threshold = 3\n",
      "[AutoTune] Step 1000: Rolling Hit Ratio = 0.72 | Threshold = 2\n",
      "[AutoTune] Step 1100: Rolling Hit Ratio = 0.76 | Threshold = 3\n",
      "[AutoTune] Step 1200: Rolling Hit Ratio = 0.68 | Threshold = 2\n",
      "[AutoTune] Step 1300: Rolling Hit Ratio = 0.73 | Threshold = 3\n",
      "[AutoTune] Step 1400: Rolling Hit Ratio = 0.72 | Threshold = 3\n",
      "[AutoTune] Step 1500: Rolling Hit Ratio = 0.74 | Threshold = 4\n",
      "[AutoTune] Step 1600: Rolling Hit Ratio = 0.77 | Threshold = 5\n",
      "[AutoTune] Step 1700: Rolling Hit Ratio = 0.7 | Threshold = 4\n",
      "[AutoTune] Step 1800: Rolling Hit Ratio = 0.82 | Threshold = 5\n",
      "[AutoTune] Step 1900: Rolling Hit Ratio = 0.7 | Threshold = 4\n",
      "[AutoTune] Step 2000: Rolling Hit Ratio = 0.73 | Threshold = 5\n",
      "[AutoTune] Step 2100: Rolling Hit Ratio = 0.71 | Threshold = 4\n",
      "[AutoTune] Step 2200: Rolling Hit Ratio = 0.78 | Threshold = 5\n",
      "[AutoTune] Step 2300: Rolling Hit Ratio = 0.72 | Threshold = 4\n",
      "[AutoTune] Step 2400: Rolling Hit Ratio = 0.7 | Threshold = 3\n",
      "[AutoTune] Step 2500: Rolling Hit Ratio = 0.72 | Threshold = 4\n",
      "[AutoTune] Step 2600: Rolling Hit Ratio = 0.79 | Threshold = 5\n",
      "[AutoTune] Step 2700: Rolling Hit Ratio = 0.77 | Threshold = 4\n",
      "[AutoTune] Step 2800: Rolling Hit Ratio = 0.78 | Threshold = 4\n",
      "[AutoTune] Step 2900: Rolling Hit Ratio = 0.75 | Threshold = 3\n",
      "[AutoTune] Step 3000: Rolling Hit Ratio = 0.75 | Threshold = 3\n",
      "[AutoTune] Step 3100: Rolling Hit Ratio = 0.75 | Threshold = 3\n",
      "[AutoTune] Step 3200: Rolling Hit Ratio = 0.73 | Threshold = 2\n",
      "[AutoTune] Step 3300: Rolling Hit Ratio = 0.74 | Threshold = 2\n",
      "[AutoTune] Step 3400: Rolling Hit Ratio = 0.75 | Threshold = 2\n",
      "[AutoTune] Step 3500: Rolling Hit Ratio = 0.72 | Threshold = 1\n",
      "[AutoTune] Step 3600: Rolling Hit Ratio = 0.69 | Threshold = 1\n",
      "[AutoTune] Step 3700: Rolling Hit Ratio = 0.72 | Threshold = 2\n",
      "[AutoTune] Step 3800: Rolling Hit Ratio = 0.63 | Threshold = 1\n",
      "[AutoTune] Step 3900: Rolling Hit Ratio = 0.69 | Threshold = 2\n",
      "[AutoTune] Step 4000: Rolling Hit Ratio = 0.74 | Threshold = 3\n",
      "[AutoTune] Step 4100: Rolling Hit Ratio = 0.65 | Threshold = 2\n",
      "[AutoTune] Step 4200: Rolling Hit Ratio = 0.8 | Threshold = 3\n",
      "[AutoTune] Step 4300: Rolling Hit Ratio = 0.71 | Threshold = 2\n",
      "[AutoTune] Step 4400: Rolling Hit Ratio = 0.73 | Threshold = 3\n",
      "[AutoTune] Step 4500: Rolling Hit Ratio = 0.79 | Threshold = 4\n",
      "[AutoTune] Step 4600: Rolling Hit Ratio = 0.72 | Threshold = 3\n",
      "[AutoTune] Step 4700: Rolling Hit Ratio = 0.65 | Threshold = 2\n",
      "[AutoTune] Step 4800: Rolling Hit Ratio = 0.63 | Threshold = 1\n",
      "[AutoTune] Step 4900: Rolling Hit Ratio = 0.63 | Threshold = 1\n",
      "[AutoTune] Step 5000: Rolling Hit Ratio = 0.69 | Threshold = 2\n",
      "\n",
      "Final Summary (Step: 5000)\n",
      "Cache Hits: 3611, Misses: 1389, Hit Ratio: 0.72\n",
      "Total Reinsertions: 538\n",
      "Final Reinsertion Threshold: 2\n",
      "P: ['66', '140', '285', '15', '90', '41', '19', '148', '146', '236', '82', '160', '57', '85', '176', '184', '179', '52', '232', '258', '227', '139', '3', '55', '298', '18', '5', '115', '197', '87', '1', '131', '271', '248', '145', '192', '159', '151', '187', '223', '202', '107', '47', '224', '207', '273', '225', '290', '6', '299']\n",
      "M: ['251', '297', '218', '253', '203', '49', '250', '111', '147', '262', '152', '93', '17', '222', '36', '221', '40', '143', '231', '12', '124', '283', '126', '110', '278', '228', '72', '154', '125', '96', '123', '88', '98', '39', '181', '83', '135', '71', '260', '230', '61', '220', '138', '235', '243', '217', '277', '121', '74', '149']\n",
      "G: ['79', '66', '60', '100', '267', '72', '221', '275', '190', '55', '61', '266', '134', '181', '90', '161', '225', '21', '149', '263', '145', '270', '166', '105', '273', '98', '177', '159', '244', '212', '76', '265', '250', '277', '36', '33', '163', '6', '243', '91', '78', '124', '207', '195', '165', '16', '230', '287', '30', '8', '264', '222', '17', '241', '217', '49', '198', '12', '43', '178', '117', '79', '118', '154', '94', '279', '223', '134', '283', '234', '106', '238', '235', '17', '254', '25', '136', '149', '294', '255', '248', '98', '120', '67', '150', '112', '212', '64', '60', '237', '293', '101', '46', '274', '229', '173', '299', '94', '65', '209']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "class S3FIFO_Cache_Adaptive:\n",
    "    def __init__(self, p_capacity, m_capacity, g_capacity, reinsertion_threshold=2, log_file=\"cache_log.csv\"):\n",
    "        self.P = deque()\n",
    "        self.M = deque()\n",
    "        self.G = deque()\n",
    "\n",
    "        self.p_capacity = p_capacity\n",
    "        self.m_capacity = m_capacity\n",
    "        self.g_capacity = g_capacity\n",
    "        self.reinsertion_threshold = reinsertion_threshold\n",
    "\n",
    "        self.cache_items = set()\n",
    "        self.access_count = defaultdict(int)\n",
    "\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "        self.reinserts = 0\n",
    "        self.access_step = 0\n",
    "\n",
    "        self.rolling_window = deque(maxlen=100)\n",
    "        self.rolling_ratios = []\n",
    "\n",
    "        self.log_file = log_file\n",
    "        self._init_log()\n",
    "\n",
    "        # Auto-tuning config\n",
    "        self.dynamic_adjust_every = 100\n",
    "        self.prev_rolling_ratio = 0.0\n",
    "        self.threshold_min = 1\n",
    "        self.threshold_max = 5\n",
    "\n",
    "    def _init_log(self):\n",
    "        with open(self.log_file, mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                \"step\", \"item\", \"status\", \"P\", \"M\", \"G\",\n",
    "                \"reinserts\", \"hit_ratio\", \"rolling_hit_ratio\", \"threshold\"\n",
    "            ])\n",
    "\n",
    "    def _log_access(self, item, status):\n",
    "        total = self.hits + self.misses\n",
    "        hit_ratio = self.hits / total if total > 0 else 0\n",
    "\n",
    "        self.rolling_window.append(1 if status.startswith(\"HIT\") else 0)\n",
    "        rolling_ratio = sum(self.rolling_window) / len(self.rolling_window)\n",
    "        self.rolling_ratios.append(rolling_ratio)\n",
    "\n",
    "        # Dynamic threshold tuning every N steps\n",
    "        if self.access_step % self.dynamic_adjust_every == 0:\n",
    "            if rolling_ratio < self.prev_rolling_ratio - 0.01:\n",
    "                self.reinsertion_threshold = max(self.threshold_min, self.reinsertion_threshold - 1)\n",
    "            elif rolling_ratio > self.prev_rolling_ratio + 0.01:\n",
    "                self.reinsertion_threshold = min(self.threshold_max, self.reinsertion_threshold + 1)\n",
    "            self.prev_rolling_ratio = rolling_ratio\n",
    "            print(f\"[AutoTune] Step {self.access_step}: Rolling Hit Ratio = {round(rolling_ratio, 4)} | Threshold = {self.reinsertion_threshold}\")\n",
    "\n",
    "        with open(self.log_file, mode='a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                self.access_step, item, status,\n",
    "                list(self.P), list(self.M), list(self.G),\n",
    "                self.reinserts,\n",
    "                round(hit_ratio, 4),\n",
    "                round(rolling_ratio, 4),\n",
    "                self.reinsertion_threshold\n",
    "            ])\n",
    "\n",
    "    def access(self, item):\n",
    "        self.access_step += 1\n",
    "        self.access_count[item] += 1\n",
    "\n",
    "        if item in self.cache_items:\n",
    "            self.hits += 1\n",
    "            if item in self.P:\n",
    "                self.P.remove(item)\n",
    "                self._add_to_main(item)\n",
    "                status = \"HIT-P → M\"\n",
    "            elif item in self.M:\n",
    "                self.M.remove(item)\n",
    "                self.M.append(item)\n",
    "                status = \"HIT-M\"\n",
    "        else:\n",
    "            self.misses += 1\n",
    "            status = \"MISS\"\n",
    "            self._add_to_probationary(item)\n",
    "\n",
    "        self._log_access(item, status)\n",
    "\n",
    "    def _add_to_probationary(self, item):\n",
    "        if len(self.P) >= self.p_capacity:\n",
    "            evicted = self.P.popleft()\n",
    "            self.cache_items.remove(evicted)\n",
    "\n",
    "            if self.access_count[evicted] >= self.reinsertion_threshold:\n",
    "                self.reinserts += 1\n",
    "                self._add_to_probationary(evicted)\n",
    "                return\n",
    "            else:\n",
    "                self._add_to_ghost(evicted)\n",
    "\n",
    "        self.P.append(item)\n",
    "        self.cache_items.add(item)\n",
    "\n",
    "    def _add_to_main(self, item):\n",
    "        if len(self.M) >= self.m_capacity:\n",
    "            evicted = self.M.popleft()\n",
    "            self.cache_items.remove(evicted)\n",
    "            self._add_to_ghost(evicted)\n",
    "\n",
    "        self.M.append(item)\n",
    "        self.cache_items.add(item)\n",
    "\n",
    "    def _add_to_ghost(self, item):\n",
    "        if len(self.G) >= self.g_capacity:\n",
    "            self.G.popleft()\n",
    "        self.G.append(item)\n",
    "\n",
    "    def display(self):\n",
    "        total = self.hits + self.misses\n",
    "        hit_ratio = self.hits / total if total > 0 else 0\n",
    "        print(f\"\\nFinal Summary (Step: {self.access_step})\")\n",
    "        print(f\"Cache Hits: {self.hits}, Misses: {self.misses}, Hit Ratio: {hit_ratio:.2f}\")\n",
    "        print(f\"Total Reinsertions: {self.reinserts}\")\n",
    "        print(f\"Final Reinsertion Threshold: {self.reinsertion_threshold}\")\n",
    "        print(f\"P: {list(self.P)}\")\n",
    "        print(f\"M: {list(self.M)}\")\n",
    "        print(f\"G: {list(self.G)}\\n\")\n",
    "\n",
    "# ---------------------------\n",
    "# Main Function to Run Trace\n",
    "# ---------------------------\n",
    "\n",
    "def generate_atlas_trace(n_requests=5000, unique_items=300):\n",
    "    trace = []\n",
    "    hot_sets = [random.sample(range(unique_items), 10) for _ in range(5)]\n",
    "    for _ in range(n_requests):\n",
    "        if random.random() < 0.7:\n",
    "            trace.append(random.choice(random.choice(hot_sets)))\n",
    "        else:\n",
    "            trace.append(random.randint(0, unique_items - 1))\n",
    "    return trace\n",
    "\n",
    "def save_trace_to_csv(trace, filename=\"atlas_trace.csv\"):\n",
    "    with open(filename, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"access_item\"])\n",
    "        for item in trace:\n",
    "            writer.writerow([item])\n",
    "\n",
    "def run_trace_from_csv(trace_file, cache):\n",
    "    with open(trace_file, mode='r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            cache.access(row[\"access_item\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Generate and save trace\n",
    "    trace = generate_atlas_trace()\n",
    "    save_trace_to_csv(trace)\n",
    "\n",
    "    # Step 2: Initialize cache and run simulation\n",
    "    cache = S3FIFO_Cache_Adaptive(\n",
    "        p_capacity=50, m_capacity=50, g_capacity=100,\n",
    "        reinsertion_threshold=2, log_file=\"atlas_log.csv\"\n",
    "    )\n",
    "\n",
    "    run_trace_from_csv(\"atlas_trace.csv\", cache)\n",
    "\n",
    "    # Step 3: Print final summary\n",
    "    cache.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8394add4-12e4-4160-b198-cde7cc8fcb64",
   "metadata": {},
   "source": [
    "Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2727bfb5-5df5-4229-8c6d-8efac8b0c05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All plots saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_cache_metrics(csv_file):\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Convert columns to numeric (handle errors safely)\n",
    "    df['step'] = pd.to_numeric(df['step'], errors='coerce')\n",
    "    df['hit_ratio'] = pd.to_numeric(df['hit_ratio'], errors='coerce')\n",
    "    df['rolling_hit_ratio'] = pd.to_numeric(df['rolling_hit_ratio'], errors='coerce')\n",
    "    df['reinserts'] = pd.to_numeric(df['reinserts'], errors='coerce')\n",
    "    df['threshold'] = pd.to_numeric(df['threshold'], errors='coerce')\n",
    "\n",
    "    # Plot 1: Hit Ratio Over Time\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df['step'], df['hit_ratio'], label='Hit Ratio', linewidth=2)\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Hit Ratio\")\n",
    "    plt.title(\"Hit Ratio Over Time\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"hit_ratio_over_time.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Plot 2: Rolling Hit Ratio\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df['step'], df['rolling_hit_ratio'], label='Rolling Hit Ratio (100 steps)', color='orange', linewidth=2)\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Rolling Hit Ratio\")\n",
    "    plt.title(\"Rolling Hit Ratio Over Time\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"rolling_hit_ratio_over_time.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Plot 3: Reinsertion Threshold Over Time\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df['step'], df['threshold'], label='Adaptive Reinsertion Threshold', color='green', linewidth=2)\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Threshold\")\n",
    "    plt.title(\"Reinsertion Threshold Over Time\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"reinsertion_threshold_over_time.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Plot 4: Cumulative Reinsertions Over Time\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df['step'], df['reinserts'], label='Cumulative Reinsertions', color='red', linewidth=2)\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Reinsertions\")\n",
    "    plt.title(\"Cumulative Reinsertions Over Time\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"reinsertions_over_time.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"✅ All plots saved successfully.\")\n",
    "\n",
    "def main():\n",
    "    csv_file = \"atlas_log.csv\"  # Change this if your file has a different name\n",
    "    plot_cache_metrics(csv_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611c3a0-43db-4879-98d5-8a44dc0fa78d",
   "metadata": {},
   "source": [
    "FIFO Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a387207-b7ca-49f7-8a5f-d9d564e82869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FIFO Cache Run Complete — Final Hit Ratio: 0.67\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "class FIFO_Cache:\n",
    "    def __init__(self, capacity, log_file=\"fifo_log.csv\"):\n",
    "        self.capacity = capacity\n",
    "        self.cache = deque()\n",
    "        self.cache_set = set()\n",
    "        self.access_step = 0\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "        self.rolling_window = deque(maxlen=100)\n",
    "        self.log_file = log_file\n",
    "        self._init_log()\n",
    "\n",
    "    def _init_log(self):\n",
    "        with open(self.log_file, mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"step\", \"item\", \"status\", \"hit_ratio\", \"rolling_hit_ratio\"])\n",
    "\n",
    "    def _log_access(self, item, status):\n",
    "        total = self.hits + self.misses\n",
    "        hit_ratio = self.hits / total if total > 0 else 0\n",
    "\n",
    "        self.rolling_window.append(1 if status == \"HIT\" else 0)\n",
    "        rolling_ratio = sum(self.rolling_window) / len(self.rolling_window)\n",
    "\n",
    "        with open(self.log_file, mode='a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                self.access_step,\n",
    "                item,\n",
    "                status,\n",
    "                round(hit_ratio, 4),\n",
    "                round(rolling_ratio, 4)\n",
    "            ])\n",
    "\n",
    "    def access(self, item):\n",
    "        self.access_step += 1\n",
    "\n",
    "        if item in self.cache_set:\n",
    "            self.hits += 1\n",
    "            status = \"HIT\"\n",
    "        else:\n",
    "            self.misses += 1\n",
    "            status = \"MISS\"\n",
    "            if len(self.cache) >= self.capacity:\n",
    "                evicted = self.cache.popleft()\n",
    "                self.cache_set.remove(evicted)\n",
    "            self.cache.append(item)\n",
    "            self.cache_set.add(item)\n",
    "\n",
    "        self._log_access(item, status)\n",
    "\n",
    "    def run_trace(self, trace_file):\n",
    "        with open(trace_file, mode='r') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                self.access(row[\"access_item\"])\n",
    "\n",
    "        print(f\"✅ FIFO Cache Run Complete — Final Hit Ratio: {self.hits / (self.hits + self.misses):.2f}\")\n",
    "\n",
    "# Optional: Generate synthetic trace if needed\n",
    "def generate_atlas_trace(n_requests=5000, unique_items=300, filename=\"atlas_trace.csv\"):\n",
    "    trace = []\n",
    "    hot_sets = [random.sample(range(unique_items), 10) for _ in range(5)]\n",
    "    for _ in range(n_requests):\n",
    "        if random.random() < 0.7:\n",
    "            trace.append(random.choice(random.choice(hot_sets)))\n",
    "        else:\n",
    "            trace.append(random.randint(0, unique_items - 1))\n",
    "\n",
    "    with open(filename, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"access_item\"])\n",
    "        for item in trace:\n",
    "            writer.writerow([item])\n",
    "    print(f\"📁 Trace generated and saved to {filename}\")\n",
    "\n",
    "# Main runner\n",
    "if __name__ == \"__main__\":\n",
    "    trace_file = \"atlas_trace.csv\"\n",
    "\n",
    "    # Generate the trace if it doesn't exist\n",
    "    try:\n",
    "        open(trace_file)\n",
    "    except FileNotFoundError:\n",
    "        generate_atlas_trace(filename=trace_file)\n",
    "\n",
    "    # Run FIFO simulation\n",
    "    fifo = FIFO_Cache(capacity=100, log_file=\"fifo_log.csv\")\n",
    "    fifo.run_trace(trace_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d472f56f-6802-4be0-b423-4b299b01eaee",
   "metadata": {},
   "source": [
    "Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9428e1a5-0526-4d45-8a0f-ec7cb6ca0168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Graphs saved as: compare_hit_ratio.png and compare_rolling_ratio.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_cache_logs(adaptive_csv, fifo_csv):\n",
    "    # Load both logs\n",
    "    adaptive = pd.read_csv(adaptive_csv)\n",
    "    fifo = pd.read_csv(fifo_csv)\n",
    "\n",
    "    # Ensure data is numeric\n",
    "    adaptive['step'] = pd.to_numeric(adaptive['step'], errors='coerce')\n",
    "    adaptive['hit_ratio'] = pd.to_numeric(adaptive['hit_ratio'], errors='coerce')\n",
    "    adaptive['rolling_hit_ratio'] = pd.to_numeric(adaptive['rolling_hit_ratio'], errors='coerce')\n",
    "\n",
    "    fifo['step'] = pd.to_numeric(fifo['step'], errors='coerce')\n",
    "    fifo['hit_ratio'] = pd.to_numeric(fifo['hit_ratio'], errors='coerce')\n",
    "    fifo['rolling_hit_ratio'] = pd.to_numeric(fifo['rolling_hit_ratio'], errors='coerce')\n",
    "\n",
    "    # Plot 1: Hit Ratio Comparison\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(adaptive['step'], adaptive['hit_ratio'], label='Adaptive Cache', linewidth=2)\n",
    "    plt.plot(fifo['step'], fifo['hit_ratio'], label='FIFO Cache', linestyle='--', linewidth=2)\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Hit Ratio\")\n",
    "    plt.title(\"Comparison of Hit Ratio: Adaptive vs FIFO\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"compare_hit_ratio.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Plot 2: Rolling Hit Ratio Comparison (Smoothed)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(adaptive['step'], adaptive['rolling_hit_ratio'].rolling(window=50).mean(), label='Adaptive Cache', linewidth=2)\n",
    "    plt.plot(fifo['step'], fifo['rolling_hit_ratio'].rolling(window=50).mean(), label='FIFO Cache', linestyle='--', linewidth=2)\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Rolling Hit Ratio (Smoothed)\")\n",
    "    plt.title(\"Comparison of Rolling Hit Ratio: Adaptive vs FIFO\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"compare_rolling_ratio.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"✅ Graphs saved as: compare_hit_ratio.png and compare_rolling_ratio.png\")\n",
    "\n",
    "def main():\n",
    "    adaptive_log = \"atlas_log.csv\"\n",
    "    fifo_log = \"fifo_log.csv\"\n",
    "    compare_cache_logs(adaptive_log, fifo_log)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fda8bd6-bdf1-44ef-8663-019f19330178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b170af8-3f8a-4b66-84e0-5c3c8779f39f",
   "metadata": {},
   "source": [
    "SNIA IOTTA Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "153b1efb-c3a9-4b64-b0a4-3dc96eea86b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed: hm_1.csv → trace_hm_1.csv\n",
      "✅ Processed: hm_0.csv → trace_hm_0.csv\n",
      "✅ Processed: mds_1.csv → trace_mds_1.csv\n",
      "✅ Processed: mds_0.csv → trace_mds_0.csv\n",
      "✅ Processed: prn_0.csv → trace_prn_0.csv\n",
      "✅ Processed: prn_1.csv → trace_prn_1.csv\n",
      "✅ Processed: proj_4.csv → trace_proj_4.csv\n",
      "✅ Processed: proj_3.csv → trace_proj_3.csv\n",
      "✅ Processed: proj_2.csv → trace_proj_2.csv\n",
      "✅ Processed: proj_0.csv → trace_proj_0.csv\n",
      "✅ Processed: proj_1.csv → trace_proj_1.csv\n",
      "✅ Processed: prxy_0.csv → trace_prxy_0.csv\n",
      "✅ Processed: prxy_1.csv → trace_prxy_1.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Step 1: Set folder path (relative to your notebook)\n",
    "input_folder = 'SNIA'\n",
    "output_folder = 'SNIA'\n",
    "\n",
    "# Step 2: Get list of all .csv files in the folder\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "\n",
    "# Step 3: Process each CSV\n",
    "for filename in csv_files:\n",
    "    input_path = os.path.join(input_folder, filename)\n",
    "    output_name = f\"trace_{filename}\"\n",
    "    output_path = os.path.join(output_folder, output_name)\n",
    "\n",
    "    with open(input_path, 'r') as infile, open(output_path, 'w', newline='') as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(['access_item'])\n",
    "\n",
    "        # Skip header if present\n",
    "        first_row = next(reader)\n",
    "        try:\n",
    "            float(first_row[0])  # Check if first value is numeric\n",
    "            infile.seek(0)       # No header; reset file\n",
    "            reader = csv.reader(infile)\n",
    "        except ValueError:\n",
    "            pass  # Header already skipped\n",
    "\n",
    "        for row in reader:\n",
    "            try:\n",
    "                device = row[1].strip()  # device_number\n",
    "                block = row[2].strip()   # block_number\n",
    "                access_item = f\"{device}:{block}\"\n",
    "                writer.writerow([access_item])\n",
    "            except IndexError:\n",
    "                continue\n",
    "\n",
    "    print(f\"✅ Processed: {filename} → {output_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e129fcaa-4a20-4bfb-b56f-c3ff00507262",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ad51d-cd00-49cc-b790-dba3efd8e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque, defaultdict\n",
    "import csv\n",
    "\n",
    "class S3FIFO_Cache_Adaptive:\n",
    "    def __init__(self, p_capacity, m_capacity, g_capacity, reinsertion_threshold=2, log_file=\"cache_log.csv\"):\n",
    "        self.P = deque()\n",
    "        self.M = deque()\n",
    "        self.G = deque()\n",
    "        self.p_capacity = p_capacity\n",
    "        self.m_capacity = m_capacity\n",
    "        self.g_capacity = g_capacity\n",
    "        self.reinsertion_threshold = reinsertion_threshold\n",
    "\n",
    "        self.cache_items = set()\n",
    "        self.access_count = defaultdict(int)\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "        self.reinserts = 0\n",
    "        self.access_step = 0\n",
    "        self.log_file = log_file\n",
    "        self._init_log()\n",
    "\n",
    "    def _init_log(self):\n",
    "        with open(self.log_file, mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"step\", \"item\", \"status\", \"P\", \"M\", \"G\", \"reinserts\", \"hit_ratio\"])\n",
    "\n",
    "    def _log_access(self, item, status):\n",
    "        total = self.hits + self.misses\n",
    "        hit_ratio = self.hits / total if total > 0 else 0\n",
    "        with open(self.log_file, mode='a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                self.access_step,\n",
    "                item,\n",
    "                status,\n",
    "                list(self.P),\n",
    "                list(self.M),\n",
    "                list(self.G),\n",
    "                self.reinserts,\n",
    "                round(hit_ratio, 4)\n",
    "            ])\n",
    "\n",
    "    def access(self, item):\n",
    "        self.access_step += 1\n",
    "        self.access_count[item] += 1\n",
    "        if item in self.cache_items:\n",
    "            self.hits += 1\n",
    "            if item in self.P:\n",
    "                self.P.remove(item)\n",
    "                self._add_to_main(item)\n",
    "                status = \"HIT-P → M\"\n",
    "            elif item in self.M:\n",
    "                self.M.remove(item)\n",
    "                self.M.append(item)\n",
    "                status = \"HIT-M\"\n",
    "        else:\n",
    "            self.misses += 1\n",
    "            status = \"MISS\"\n",
    "            self._add_to_probationary(item)\n",
    "        self._log_access(item, status)\n",
    "\n",
    "    def _add_to_probationary(self, item):\n",
    "        if len(self.P) >= self.p_capacity:\n",
    "            evicted = self.P.popleft()\n",
    "            self.cache_items.remove(evicted)\n",
    "            if self.access_count[evicted] >= self.reinsertion_threshold:\n",
    "                self.reinserts += 1\n",
    "                self._add_to_probationary(evicted)\n",
    "                return\n",
    "            else:\n",
    "                self._add_to_ghost(evicted)\n",
    "        self.P.append(item)\n",
    "        self.cache_items.add(item)\n",
    "\n",
    "    def _add_to_main(self, item):\n",
    "        if len(self.M) >= self.m_capacity:\n",
    "            evicted = self.M.popleft()\n",
    "            self.cache_items.remove(evicted)\n",
    "            self._add_to_ghost(evicted)\n",
    "        self.M.append(item)\n",
    "        self.cache_items.add(item)\n",
    "\n",
    "    def _add_to_ghost(self, item):\n",
    "        if len(self.G) >= self.g_capacity:\n",
    "            self.G.popleft()\n",
    "        self.G.append(item)\n",
    "\n",
    "    def display(self):\n",
    "        total = self.hits + self.misses\n",
    "        hit_ratio = self.hits / total if total > 0 else 0\n",
    "        print(f\"Step: {self.access_step}\")\n",
    "        print(f\"Cache Hits: {self.hits}, Misses: {self.misses}, Hit Ratio: {hit_ratio:.2f}\")\n",
    "        print(f\"Reinsertions: {self.reinserts}\")\n",
    "        print(f\"P: {list(self.P)}\\nM: {list(self.M)}\\nG: {list(self.G)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7cef6a-7967-4b43-a74d-e08fd885118a",
   "metadata": {},
   "source": [
    "Step 2: Create a cache object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90cb607f-62b8-4286-b499-692de872702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = S3FIFO_Cache_Adaptive(\n",
    "    p_capacity=50, \n",
    "    m_capacity=50, \n",
    "    g_capacity=100, \n",
    "    reinsertion_threshold=2,\n",
    "    log_file=\"cache_log_hm0.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a83d81-0131-45c1-8d66-e5cdc1dec3b1",
   "metadata": {},
   "source": [
    "Step 3: Load the trace + simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bcdaac4-0948-44e2-b803-7e882937fdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3993316\n",
      "Cache Hits: 3993315, Misses: 1, Hit Ratio: 1.00\n",
      "Reinsertions: 0\n",
      "P: []\n",
      "M: ['hm:0']\n",
      "G: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_trace_csv(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        return [row[0] for row in reader]\n",
    "\n",
    "trace = load_trace_csv(\"SNIA/trace_hm_0.csv\")\n",
    "\n",
    "for item in trace:\n",
    "    cache.access(item)\n",
    "\n",
    "cache.display()  # Final stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b827a3d7-fc73-49cd-adc3-5d203665c796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4602627\n",
      "Cache Hits: 4602625, Misses: 2, Hit Ratio: 1.00\n",
      "Reinsertions: 0\n",
      "P: []\n",
      "M: ['hm:0', 'hm:1']\n",
      "G: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_trace_csv(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        return [row[0] for row in reader]\n",
    "\n",
    "trace = load_trace_csv(\"SNIA/trace_hm_1.csv\")\n",
    "\n",
    "for item in trace:\n",
    "    cache.access(item)\n",
    "\n",
    "cache.display()  # Final stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2960b662-5b93-4ef7-b10b-37362404ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trace_csv(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        return [row[0] for row in reader]\n",
    "\n",
    "trace = load_trace_csv(\"SNIA/trace_hm_0.csv\")\n",
    "\n",
    "for item in trace:\n",
    "    cache.access(item)\n",
    "\n",
    "cache.display()  # Final stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05747609-e281-4d74-8fa9-7295ee3441da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f2ed8a-f60d-422a-b7d0-f4e948278dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3b357-88b7-4656-99ef-24cd95327138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10264b-0d44-468b-b0c9-702f0496c62f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d4945-c894-48ff-b4de-01f98af6011b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c0ee35-febe-4ab0-8fa7-0bdc2c783dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d9ac29-ecd6-4659-a3aa-66cdd6d424a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e023bc03-5b7f-4192-9d94-99d39bd41d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063226be-9292-40c1-8c33-be897b39dcac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
